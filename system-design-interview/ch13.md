# CH13 검색어 자동 완성 시스템

## 요구 사항

- 빠른 응답 속도 : 시스템 응답 속도 100ms 이내
- 연관성 : 자동완성 키워드는 입력값과 연관 있어야 함
- 정렬 : 인기도와 순위 모델 기준으로 정렬 필요
- 규모 확장성 : 많은 트래픽을 감당 가능 하도록 해야함
- 고가용성 : 시스템의 일부가 장애가 발생하거나 느려져도 사용 가능해야 함

### 개략적 규모 추정

- DAU : 천만 건
- 1회 검색 당 20건의 요청 전달
- 질의 가운데 20%가 새로운 요청

## 설계안 제시

### 데이터 수집 서비스

- 빈도 테이블을 생성하여 검색에 따른 카운트를 매기는 테이블

### 질의 서비스

- 각 질의 문에 대한 빈도를 저장하는 필드
- 데이터량이 아주 많아지면 DB에 병목이 생길 수도 있음

## 상세 설계

- 트라이 자료 구조
- 데이터 수집 서비스
- 질의 서비스

### 트라이 자료구조

- 트리형태의 자료구조
- 루트 노드는 빈 형태의 자료 구조
- 각 노드는 글자를 하나 씩 저장하고 자식 노드를 가질 수 있음
- 각 트리 노드는 prefix로 접두어 문자열을 가짐

### 구현 방법

1. 해당 검색어에 해당하는 트리를 검색 - O(p) : p - 접두어 길이
2. 검색어가 완성되는 유효 노드 찾기 - O(c) : 트라이 내에 있는 노드 수
3. 유효 노드를 검사하여 인기 검색어를 검색 - O(clogc)

- 직관적이지만, 최악의 경우에는 너무 길어질 가능성 존재

    1. 최대 길이를 제한
    2. 각 노드에 인기 검색어 캐시

#### 접두어 최대 길이 제한

- 접두어 길이를 제한하면 전체 순회가 아니기 때문에 O(1)로 바뀜

#### 노드 인기 검색어 제시

- 5 ~ 10개 정도의 인기 질의어를 표시하면 충분하므로, 해당 내용을 노드 중간에 캐싱하여 해당 데이터를 가져가도록 구성

- 위 방법 사용시 접두어를 검색하거나 인기 검색어를 찾는 방법에 있어 O(1)로 변하게 된다

#### 데이터 수집 서비스

- 한번 만들어진 트라이는 자주 갱신 될 필요성이 적음
- 매번 갱신 될 경우 질의 서비스가 매우 느려질 가능성 존재

## 개선안

- 데이터 분석 로그에서 로그 취합 서버에 데이터를 보내고 취합된 데이터를 작업서버로 보냄
- 주 단위로 트라이를 갱신 + 캐싱

### 데아터 분석 서비스 로그

- 분석 서비스로그는 이벤트 소싱만 담당하여 데이터 내에 로그 데이터에 대한 append만 이루어지도록 설계
- 로그 취합 서버는 (Logstash) 데이터를 aggregation하여 시스템에서 소비할 수 있도록 데이터를 정제
    - 취합 된 데이터는 1. 쿼리 2. 시간대 3. 빈도수를 통해서 정제

### 작업 서버

- 주기적으로 비동기적으로 작업하는 서버의 집합 모음
- 트라이 자료 구조를 생성하고 데이터 베이스에 해당 자료 구조를 저장하는 역할 담당

### 트라이 캐시

- 분산 캐시 시스템으로 트라이 데이터를 메모리에 유지하여 읽기 연산 성능을 높히는 역할을 함

### 트라이 데이터 베이스

1. 문서 저장소 : NoSQL 기반 저장소 ex) 몽고DB
2. Key-Value 저장소 : 트라이에 보관된 접두어를 키값으로 두고 캐시된 데이터 및 실 데이터를 value로 저장하여 대응 할 수 있음

## 트라이 연산

### 트라이 생성

- 작업 서버가 생성

### 트라이 갱신

1. 매주 한 번 씩 갱신
2. 트라이에 각 노드를 개별적으로 갱신 -> 상위에 있는 모든 항목을 갱신아므로 성능이 좋지 않음

### 검색어 삭제

1. API 서버와 캐시 간에 필터링 계층을 삽입하여 필터링 진행

## 저장소 규모 확장

- 글자 별로 샤딩을 하는 방법 제안
- 각 클러스터 별로 검색어의 수가 다르기 때문에 과거 이력 분석을 통한 샤딩 필요
- 어느 샤드에 있는지 검색어 관리자 (인덱스 느낌) - 데이터 추출 DB 분리

## 마무리

- 유니코드 지원 (다국어)
- 국가별 순위 (다른 트라이)
- 실시간 검색어
    - 샤딩을 통한 데이터 줄이기
    - 순위 모델 바꾸기(최근 검색어 가중치)
    - 다른 DB 구조 사용


