# ch10 일괄 처리

- 시스템의 3가지 분류
    - 서비스 (온라인 시스템)
        - 클라이언트의 응답을 대기하고 회신하는 시스템
        - 성능 = response time + 가용성
    - 일괄 처리 시스템 (오프라인 시스템)
        - 큰 입력 데이터를 받아 작업 수행 후 데이터 생산
        - 성능 = 처리량
    - 스트림 처리 시스템 (준실시간 시스템)
        - 입력이 발생 후 입력 데이터를 소비하여 출력 데이터 생산

- 맵 리듀스 및 기타 일괄 처리 알고리즘 및 프레임워크 확인을 위한 장

## 유닉스 도구로 일괄 처리하기

### 단순 로그 분석

- Sample

```
cat /var/log/nginx/access.log | \
  awk '{print $7}' | \ # 7번째 필드 출력 ($0은 전체)
  sort  | \ # 정렬
  uniq -c | \ # 중복 제거 ('-c': 중복횟수 첫번째로 함께 출력) 
  sort -r -n | \ # 정렬 ('-r': 내림차순, '-n' : 숫자로 정렬)
  head -n 5 # 맨 앞 5줄만 출력
```

- 유닉스 도구의 조합을 통해 많은 데이터 분석 가능

#### 연쇄 명령 대 맞춤형 프로그램

- 맞춤형 프로그래밍의 경우 연쇄 명령보다 코드가 더 길지만 읽기는 쉬움

#### 정렬 대 인메모리 집계

- 루비 스크립트는 URL을 Hash Table에 적재
- 유닉스 파이프 라인은 URL을 명령어 마다 기입
- 특징
    - 작업 세트가 작을 경우 Hash Table을 쓰는 것도 나쁘지 않음
    - 메모리 보다 작업 세트가 클 경우 정렬 접근법을 사용하는 것이 좋음
        - 데이터 청크를 정렬하여 세그먼트 파일로 디스크에 저장
        - 세그먼트 파일을 큰 정렬 파일로 병합
        - 위 작업을 통해 큰 데이터셋으로 확장 가능

### 유닉스 철학

- 유닉스 철학의 방식
    1. 각 프로그램은 하나의 일 만하도록 작성
    2. 모든 프로그램의 출력은 알려지지 않은 프로그래밍의 입력으로 사용 가능
    3. S/W 및 OS는 빠르게 써볼 수 있도록 구축해야 함
    4. 프로그래밍 작업을 줄이기 위해서는 도구를 사용하라
- Agile 방식 및 DevOps 운동과 비슷


#### 동일 인터페이스

- 특정 출력을 다른 입력으로 쓰려면 모두 호환 가능한 인터페이스 사용 필요
- 관례 상 연속된 바이트를 아스키 바이트 취급
- 유닉스는 같은 레코드 분리자를 사용하여 표준화 하였음
- 유닉스의 통합 인터페이스는 이종 간 데이터가 이동이 유용하게 구축 되어 있음
    - 이와 다르게 데이터베이스는 시스템 간 발칸화(갈라파고스 현상)

#### 로직과 연결의 분리

- 표준 입력과 출력 사용
    - 디스크에 쓰지 않고 작은 인메모리 버퍼를 이용하여 데이터를 전송
- 입출력을 신경 쓰지 않고 연결
    - 느슨한 결합
    - 지연 바인딩
    - 제어 바인딩
- 프로그램을 직접 작성하여 운영체제에서 지원하는 도구와 같이 사용 가능
- 제약 사항
    - 여러 입력 및 출력이 필요할 때 까다로움
    - 네트워크 작업이나 I/O를 묶을 경우 유연함은 감소

#### 투명성과 실험

- 유닉스 도구는 불친절하고 단순하지만, 진행 사항 파악이 쉬움
    - 입력 파일은 불변 처리
    - 파이프라인 중단 후 출력 확인 가능
    - 파이프라인 확인 시 데이터를 파일에 저장하고 다음 단계를 추후 재시작 가능
- 가장 큰 제약은 단일 장비에서만 실행 가능

## 맵 리듀스와 분산 파일 시스템

- MapReduce는 Unix 도구와 비슷하지만 수천 대의 장비로 분산해서 실행 가능
    - 입력을 수정하지 않으므로 출력에 대해 부수적인 효과는 없음
- 맵 리듀스 작업은 분산 파일 시스템(HDFS) 파일을 입력과 출력으로 사용
- HDFS는 비공유 원칙을 기반
    - 공유 디스크 방식과는 반대
    - 공유 방식과는 다르게 중앙 집중 저장 방식이나 특별한 네트워크 인프라를 쓰지 않음
- HDFS는 개념적으로 매우 큰 하나의 파일 시스템
    - 각 장비에서 실행되는 데몬 프로세스 구성
    - 네임 노드라는 중앙 서버를 통해 장비 저장을 추적
- 삭제 코딩 방식을 이용해서 적은 저장소 부담으로 손실된 데이터를 복제
    - RAID처럼 여러 디스크를 통해 중복을 제공
- HDFS는 뛰어난 확장성을 가지고 있고 범용 하드웨어 및 오픈 소스 소프트웨어 사용 가능

- 삭제 코딩

```
n개의 데이터 셀에서 k개의 패러티 셀 데이터로 인코딩하고,
데이터 손실시 디코딩 과정을 거쳐 원본 데이터를 복구하는 데이터 복구 기법 중 하나 (백업 목적 X)
(XOR 방식, Reed-Solomon(RS) code)

장점

스토리지 효율성 👍🏻: n/(n+k)
(단, EC는 데이터 크기에 따라 Namenode에 더욱 많은 블록 정보를 관리를 요구하게 됨으로 오버헤드 존재)
제약사항

지역성(data locality) x
overwrite가 많은 환경엔 추천 x
4개 이상의 노드일때만 사용 가능
```
[출처](https://minsw.github.io/2021/06/15/Designing-Data-Intensive-Applications-10/)

### 맵리듀스 작업 실행하기

- 분산 시스템 상에서 대용량 데이터셋을 처리하는 코드
    1. 입력파일을 레코드 별로 \n을 분리자로 사용하여 쪼갬
    2. 각 레코드마다 매퍼 함수를 호출하여 키와 값을 추출
    3. 키 기준으로 키-값 쌍 정렬
    4. 정렬된 키-쌍 전체를 대상으로 리듀스 함수를 호출
- 맵 리듀스 작업 4단계
    1. 레코드를 만들기 위해입력 형식 파서 사용
    2. 맵 단계에서는 레코드로 부터 키와 값을 추출
    3. 정렬 단계에서는 내부적으로 출력을 정렬
    4. 리듀스 단계에서는 키-값 쌍을 받아 출력 레코드 생산

#### 맵리듀스의 분산 실행

- 유닉스 파이프 라인과는 다르게 병렬 수행 코드를 직접 작성하지 않고도 여러 장비에서 동시 처리 가능
- Mapper과 Reducer를 표준 유닉스 도구를 사용하는 것 또한 가능
- Map-Reduce 작업의 병렬 실행은 Partitioning 기반으로 진행
    - 어느 Reduce Task에서 수행될지 결정하기 위해서는 Key의 Hash 값을 사용
    - Reducer 기준으로 Partitioning 하고 정렬 후 데이터 파티션에 복제 - Shuffle
    - 위 과정에서 정렬된 순서를 유지하면서 병합

#### Map-Reduce Workflow

- Map-Reduce는 중간 워크플로를 직접 제공하지 않기 때문에 두 워크플로를 입력과 출력으로 받도록 설정해야 함
- 각 작업을 임시 파일에 저장하고 가져는 방식
- 일괄 처리 작업의 출력은 모든 작업이 끝나야만 유효

### 리듀스 사이드 조인과 그룹화

- 조인의 구현 방식
    - RDBMS에서의 외래키, 문서 참조에 해당
    - 전체 테이블 스캔- 입력 파일 전체 내용을 읽고 비용이 많이 듬

#### 사용자 활동 이벤트 분석 예제

- 가장 좋은 방법은 데이터베이스 사본을 ETL을 통해 추출
    - 분산 파일 시스템에 넣음

#### 정렬 병합 조인

- 매퍼 출력이 키로 정렬된 이후 조인의 양측에 레코드 목록 병합
- 리듀서가 작업 레코드를 재배열처리 - <b>보조 정렬</b>
- 특정 id의 Record를 한 번에 처리, 한 번에 한 레코드만 유지
- 키로 정렬 이후 Reducer가 조인 양측의 정렬도니 레코드 목록을 병합

#### 그룹화

- 집계 연산의 예
    - 각 그룹의 레코드 수 카운트
    - 필드 내 모든 값을 더하기
    - 랭킹 함수 실행 시 상위 K개 레코드 고르기
- 세션화
    - 그룹화 할 대상을 키 값으로 설정
    - 어떤 마케팅 활동이 가치 있는 지 분석

#### 쏠림 다루기

- 불균형한 활성 데이터베이스레코드 - <b>핫 키 / 린치핀 객체 </b>
- 위 케이스를 해소하기 위한 알고리즘
    - 쏠린 조인 메소드
        - 샘플링 작업을 하여 핫 키를 가진 레코드를 임의로 선택하여 전송
    - Crunch 공유 조인
        - 핫 키를 명시적으로 지정하여 전송
    - Hive 맵-사이드 조인
        - 테이블 메타데이터에 명시적으로 지정
        - 핫키와 관련된 레코드를 별도 파일에 저장
- 핫 키를 처리하는 로직 2단계
    1. 임의의 리듀서로 보내 핫 키 레코드 일부를 그룹화 후 간소화 값 출력
    2. 모든 리듀서에서 나온 값을 키 별로 결합하여 하나의 값으로 만듬

### 맵 사이드 조인

- 조인 로직이 실제 수해되는 곳은 Reducer 부분이기 때문에 Reduce Side Join
    - 입력 데이터에 대한 특정한 가정 필요 X
- 맵사이드 조인
    - 조인을 더 빠르게 수행하기 위한 방법
    - Reducer 및 정렬 X
    - Mapper가 입력 파일 블럭 하나를 읽어 분산 파일 시스템에 출력

#### 브로드캐스트 해시 조인

- 작은 데이터 셋과 큰 데이터 셋을 적용 시 간단하게 적용 가능
- 큰 파티션을 담당하는 Mapper가 작은 입력 전체를 읽음 (Broadcast)
- Hash 테이블을 사용
- 인메모리 해시 테이블 만큼 임의 접근 조회 가능

#### 파티션 해시 조인

- 활동 이벤트와 DB를 기준으로 파티셔닝해 재배열
- 같은 키, 해시 함수로 파티셔닝하여 조인
- 각 Mapper 별 Hash Table에 적재해야 할 데이터 양을 줄이는 것이 장점

#### 맵 사이드 병합 조인

- 입력 데이터 셋이 같은 방시긍로 파티셔닝되고, 같은 키를 기준으로 정렬 할 경우 사용 가능
- 오름차순으로 양쪽 데이터를 읽음
- 맵 전용 작업에서 정렬 수행

#### 맵 사이드 조인을 사용하는 맵리듀스 워크 플로

- Reduce Side Join
    - Join Key로 Partitioning, Sorting
- Map Side Join
    - 큰 조인 입력과 같은 방식으로 Partitioning, Sorting

### 일괄 처리 워크플로의 출력

- OLAP의 목적
    - 대량의 레코드를 스캔하여 그룹화하여 보고서 형태로 출력
    - 일괄처리의 경우 분석에 가까움

#### 검색 색인 구축

- 정해진 문서 집합을 대상으로 한 전문 검색이 필요할 경우 일괄 처리가 효율적임
- 병렬화가 잘 됨, 색인 파일을 한번 생성하면 불변

#### 일괄 처리의 출력으로 키-값을 저장

- 예시 : 검색 색인, 머신러닝 분류 시스템, 추천 시스템
- 일괄 처리의 출력 => 일종의 데이터 베이스
- 질의 방법
    - 일괄 처리 작업이 한번에 하나의 레코드 씩 서버로 직접 요청 전달 - 효율이 떨어짐
    - 일괄 처리 작업 내부에 새로운 DB를 구축하여 분산 파일 시스템 출력 디렉터리에 저장
- 데이터 파일을 한 번 기록 되면 불변이고 서버에 벌크로 저장하여 읽기 전용 질의 처리 가능
- 복사를 완료 시 새 파일로 저장

#### 일괄 처리 출력에 대한 철학

- 인적 내결함성 : 버그 있는 코드에서의 복원 가능 여부
- 비가역성 최소화 : 실수해도 되돌릴 수 있는 경우 기능 개발이 빨라짐
- 실패한 출력은 폐기함 / 입력은 불변
- 동일 입력 파일 집합 사용
- 연결 작업과 로직을 분리

### 하둡과 분산 데이터베이스 비교

## 맵 리듀스를 넘어
### 중간 상태 구체화
### 고수준 API와 언어