# ch10 일괄 처리

- 시스템의 3가지 분류
    - 서비스 (온라인 시스템)
        - 클라이언트의 응답을 대기하고 회신하는 시스템
        - 성능 = response time + 가용성
    - 일괄 처리 시스템 (오프라인 시스템)
        - 큰 입력 데이터를 받아 작업 수행 후 데이터 생산
        - 성능 = 처리량
    - 스트림 처리 시스템 (준실시간 시스템)
        - 입력이 발생 후 입력 데이터를 소비하여 출력 데이터 생산

- 맵 리듀스 및 기타 일괄 처리 알고리즘 및 프레임워크 확인을 위한 장

## 유닉스 도구로 일괄 처리하기

### 단순 로그 분석

- Sample

```
cat /var/log/nginx/access.log | \
  awk '{print $7}' | \ # 7번째 필드 출력 ($0은 전체)
  sort  | \ # 정렬
  uniq -c | \ # 중복 제거 ('-c': 중복횟수 첫번째로 함께 출력) 
  sort -r -n | \ # 정렬 ('-r': 내림차순, '-n' : 숫자로 정렬)
  head -n 5 # 맨 앞 5줄만 출력
```

- 유닉스 도구의 조합을 통해 많은 데이터 분석 가능

#### 연쇄 명령 대 맞춤형 프로그램

- 맞춤형 프로그래밍의 경우 연쇄 명령보다 코드가 더 길지만 읽기는 쉬움

#### 정렬 대 인메모리 집계

- 루비 스크립트는 URL을 Hash Table에 적재
- 유닉스 파이프 라인은 URL을 명령어 마다 기입
- 특징
    - 작업 세트가 작을 경우 Hash Table을 쓰는 것도 나쁘지 않음
    - 메모리 보다 작업 세트가 클 경우 정렬 접근법을 사용하는 것이 좋음
        - 데이터 청크를 정렬하여 세그먼트 파일로 디스크에 저장
        - 세그먼트 파일을 큰 정렬 파일로 병합
        - 위 작업을 통해 큰 데이터셋으로 확장 가능

### 유닉스 철학

- 유닉스 철학의 방식
    1. 각 프로그램은 하나의 일 만하도록 작성
    2. 모든 프로그램의 출력은 알려지지 않은 프로그래밍의 입력으로 사용 가능
    3. S/W 및 OS는 빠르게 써볼 수 있도록 구축해야 함
    4. 프로그래밍 작업을 줄이기 위해서는 도구를 사용하라
- Agile 방식 및 DevOps 운동과 비슷


#### 동일 인터페이스

- 특정 출력을 다른 입력으로 쓰려면 모두 호환 가능한 인터페이스 사용 필요
- 관례 상 연속된 바이트를 아스키 바이트 취급
- 유닉스는 같은 레코드 분리자를 사용하여 표준화 하였음
- 유닉스의 통합 인터페이스는 이종 간 데이터가 이동이 유용하게 구축 되어 있음
    - 이와 다르게 데이터베이스는 시스템 간 발칸화(갈라파고스 현상)

#### 로직과 연결의 분리

- 표준 입력과 출력 사용
    - 디스크에 쓰지 않고 작은 인메모리 버퍼를 이용하여 데이터를 전송
- 입출력을 신경 쓰지 않고 연결
    - 느슨한 결합
    - 지연 바인딩
    - 제어 바인딩
- 프로그램을 직접 작성하여 운영체제에서 지원하는 도구와 같이 사용 가능
- 제약 사항
    - 여러 입력 및 출력이 필요할 때 까다로움
    - 네트워크 작업이나 I/O를 묶을 경우 유연함은 감소

#### 투명성과 실험

- 유닉스 도구는 불친절하고 단순하지만, 진행 사항 파악이 쉬움
    - 입력 파일은 불변 처리
    - 파이프라인 중단 후 출력 확인 가능
    - 파이프라인 확인 시 데이터를 파일에 저장하고 다음 단계를 추후 재시작 가능
- 가장 큰 제약은 단일 장비에서만 실행 가능

## 맵 리듀스와 분산 파일 시스템

- MapReduce는 Unix 도구와 비슷하지만 수천 대의 장비로 분산해서 실행 가능
    - 입력을 수정하지 않으므로 출력에 대해 부수적인 효과는 없음
- 맵 리듀스 작업은 분산 파일 시스템(HDFS) 파일을 입력과 출력으로 사용
- HDFS는 비공유 원칙을 기반
    - 공유 디스크 방식과는 반대
    - 공유 방식과는 다르게 중앙 집중 저장 방식이나 특별한 네트워크 인프라를 쓰지 않음
- HDFS는 개념적으로 매우 큰 하나의 파일 시스템
    - 각 장비에서 실행되는 데몬 프로세스 구성
    - 네임 노드라는 중앙 서버를 통해 장비 저장을 추적
- 삭제 코딩 방식을 이용해서 적은 저장소 부담으로 손실된 데이터를 복제
    - RAID처럼 여러 디스크를 통해 중복을 제공
- HDFS는 뛰어난 확장성을 가지고 있고 범용 하드웨어 및 오픈 소스 소프트웨어 사용 가능

- 삭제 코딩

```
n개의 데이터 셀에서 k개의 패러티 셀 데이터로 인코딩하고,
데이터 손실시 디코딩 과정을 거쳐 원본 데이터를 복구하는 데이터 복구 기법 중 하나 (백업 목적 X)
(XOR 방식, Reed-Solomon(RS) code)

장점

스토리지 효율성 👍🏻: n/(n+k)
(단, EC는 데이터 크기에 따라 Namenode에 더욱 많은 블록 정보를 관리를 요구하게 됨으로 오버헤드 존재)
제약사항

지역성(data locality) x
overwrite가 많은 환경엔 추천 x
4개 이상의 노드일때만 사용 가능
```
[출처](https://minsw.github.io/2021/06/15/Designing-Data-Intensive-Applications-10/)

### 맵리듀스 작업 실행하기

- 분산 시스템 상에서 대용량 데이터셋을 처리하는 코드
    1. 입력파일을 레코드 별로 \n을 분리자로 사용하여 쪼갬
    2. 각 레코드마다 매퍼 함수를 호출하여 키와 값을 추출
    3. 키 기준으로 키-값 쌍 정렬
    4. 정렬된 키-쌍 전체를 대상으로 리듀스 함수를 호출
- 맵 리듀스 작업 4단계
    1. 레코드를 만들기 위해입력 형식 파서 사용
    2. 맵 단계에서는 레코드로 부터 키와 값을 추출
    3. 정렬 단계에서는 내부적으로 출력을 정렬
    4. 리듀스 단계에서는 키-값 쌍을 받아 출력 레코드 생산

#### 맵리듀스의 분산 실행

- 유닉스 파이프 라인과는 다르게 병렬 수행 코드를 직접 작성하지 않고도 여러 장비에서 동시 처리 가능
- Mapper과 Reducer를 표준 유닉스 도구를 사용하는 것 또한 가능
- Map-Reduce 작업의 병렬 실행은 Partitioning 기반으로 진행
    - 어느 Reduce Task에서 수행될지 결정하기 위해서는 Key의 Hash 값을 사용
    - Reducer 기준으로 Partitioning 하고 정렬 후 데이터 파티션에 복제 - Shuffle
    - 위 과정에서 정렬된 순서를 유지하면서 병합

#### Map-Reduce Workflow

- Map-Reduce는 중간 워크플로를 직접 제공하지 않기 때문에 두 워크플로를 입력과 출력으로 받도록 설정해야 함
- 각 작업을 임시 파일에 저장하고 가져는 방식
- 일괄 처리 작업의 출력은 모든 작업이 끝나야만 유효

### 리듀스 사이드 조인과 그룹화

- 조인의 구현 방식
    - RDBMS에서의 외래키, 문서 참조에 해당
    - 전체 테이블 스캔- 입력 파일 전체 내용을 읽고 비용이 많이 듬

#### 사용자 활동 이벤트 분석 예제

- 가장 좋은 방법은 데이터베이스 사본을 ETL을 통해 추출
    - 분산 파일 시스템에 넣음

#### 정렬 병합 조인

- 매퍼 출력이 키로 정렬된 이후 조인의 양측에 레코드 목록 병합
- 리듀서가 작업 레코드를 재배열처리 - <b>보조 정렬</b>
- 특정 id의 Record를 한 번에 처리, 한 번에 한 레코드만 유지
- 키로 정렬 이후 Reducer가 조인 양측의 정렬도니 레코드 목록을 병합

#### 그룹화

- 집계 연산의 예
    - 각 그룹의 레코드 수 카운트
    - 필드 내 모든 값을 더하기
    - 랭킹 함수 실행 시 상위 K개 레코드 고르기
- 세션화
    - 그룹화 할 대상을 키 값으로 설정
    - 어떤 마케팅 활동이 가치 있는 지 분석

#### 쏠림 다루기

- 불균형한 활성 데이터베이스레코드 - <b>핫 키 / 린치핀 객체 </b>
- 위 케이스를 해소하기 위한 알고리즘
    - 쏠린 조인 메소드
        - 샘플링 작업을 하여 핫 키를 가진 레코드를 임의로 선택하여 전송
    - Crunch 공유 조인
        - 핫 키를 명시적으로 지정하여 전송
    - Hive 맵-사이드 조인
        - 테이블 메타데이터에 명시적으로 지정
        - 핫키와 관련된 레코드를 별도 파일에 저장
- 핫 키를 처리하는 로직 2단계
    1. 임의의 리듀서로 보내 핫 키 레코드 일부를 그룹화 후 간소화 값 출력
    2. 모든 리듀서에서 나온 값을 키 별로 결합하여 하나의 값으로 만듬

### 맵 사이드 조인

- 조인 로직이 실제 수해되는 곳은 Reducer 부분이기 때문에 Reduce Side Join
    - 입력 데이터에 대한 특정한 가정 필요 X
- 맵사이드 조인
    - 조인을 더 빠르게 수행하기 위한 방법
    - Reducer 및 정렬 X
    - Mapper가 입력 파일 블럭 하나를 읽어 분산 파일 시스템에 출력

#### 브로드캐스트 해시 조인

- 작은 데이터 셋과 큰 데이터 셋을 적용 시 간단하게 적용 가능
- 큰 파티션을 담당하는 Mapper가 작은 입력 전체를 읽음 (Broadcast)
- Hash 테이블을 사용
- 인메모리 해시 테이블 만큼 임의 접근 조회 가능

#### 파티션 해시 조인

- 활동 이벤트와 DB를 기준으로 파티셔닝해 재배열
- 같은 키, 해시 함수로 파티셔닝하여 조인
- 각 Mapper 별 Hash Table에 적재해야 할 데이터 양을 줄이는 것이 장점

#### 맵 사이드 병합 조인

- 입력 데이터 셋이 같은 방시긍로 파티셔닝되고, 같은 키를 기준으로 정렬 할 경우 사용 가능
- 오름차순으로 양쪽 데이터를 읽음
- 맵 전용 작업에서 정렬 수행

#### 맵 사이드 조인을 사용하는 맵리듀스 워크 플로

- Reduce Side Join
    - Join Key로 Partitioning, Sorting
- Map Side Join
    - 큰 조인 입력과 같은 방식으로 Partitioning, Sorting

### 일괄 처리 워크플로의 출력

- OLAP의 목적
    - 대량의 레코드를 스캔하여 그룹화하여 보고서 형태로 출력
    - 일괄처리의 경우 분석에 가까움

#### 검색 색인 구축

- 정해진 문서 집합을 대상으로 한 전문 검색이 필요할 경우 일괄 처리가 효율적임
- 병렬화가 잘 됨, 색인 파일을 한번 생성하면 불변

#### 일괄 처리의 출력으로 키-값을 저장

- 예시 : 검색 색인, 머신러닝 분류 시스템, 추천 시스템
- 일괄 처리의 출력 => 일종의 데이터 베이스
- 질의 방법
    - 일괄 처리 작업이 한번에 하나의 레코드 씩 서버로 직접 요청 전달 - 효율이 떨어짐
    - 일괄 처리 작업 내부에 새로운 DB를 구축하여 분산 파일 시스템 출력 디렉터리에 저장
- 데이터 파일을 한 번 기록 되면 불변이고 서버에 벌크로 저장하여 읽기 전용 질의 처리 가능
- 복사를 완료 시 새 파일로 저장

#### 일괄 처리 출력에 대한 철학

- 인적 내결함성 : 버그 있는 코드에서의 복원 가능 여부
- 비가역성 최소화 : 실수해도 되돌릴 수 있는 경우 기능 개발이 빨라짐
- 실패한 출력은 폐기함 / 입력은 불변
- 동일 입력 파일 집합 사용
- 연결 작업과 로직을 분리

### 하둡과 분산 데이터베이스 비교

- 대규모 병렬 처리 데이터베이스에서 이미 구현
- 다만 호환성에 있어 맵리듀스가 앞섬

#### 저장소의 다양성

- 데이터베이스는 모델에 따라 데이터 구조화 필요한 상태
- 이에 비해 하둠은 어떤 형태 관련 없이 HDFS로 덤프
    -  그 이후에나 데이터 처리 생각
- DW의 개념과 마찬가지로 한 곳에 모으는 작업만으로 큰 가치
- 데이터 해석에 대한 부담을 이전
- ETL을 구현하는 데도 사용

#### 처리 모델의 다양성

- MPP 데이터 베이스는 모놀리틱 구조
    - 설계된 질의 유형에는 좋은 성능을 얻기 가능
    - SQL 질의로 모든 종류 처리 불가능
- HDFS + Map-Reduce를 이용해서 SQL을 대체 가능
- 위 모델로는 한계가 많아 다양한 모델을 사용해서 대체 (ex. Habase, Impala)

#### 빈번하게 발생하는 결함을 줄이는 설계

- Map-Reduce VS MPP Database
    - 결함을 다루는 방식
    - 메모리 및 디스크 사용 방식
- MPP는 한 장비만 죽어도 질의 전체가 중단 되는 형태
- Map-Reduce는 각각의 Task에 대해 큰 영향 X / 디스크에 데이터를 기록
- Map-Reduce는 대용량 작업과 태스크 종료가 빈번할 경우 적함

## 맵 리듀스를 넘어

- Map-Reduce는 여러 프로그래밍 모델 중 하나이므로 종속될 필요 X

### 중간 상태 구체화

- Map-Reduce는 다른 작업과 독립적
- 중간 상태를 디스크에 파일로 기록
    - 내구성을 장점으로 가짐
    - Linear하기 때문에 선행 작업 종료 대기 필요
    - Mapper Duplicate issue
    - 중간 데이터 중첩 문제

#### DataFlow Engine

- 분산 일괄 처리 연산 엔진
    - 전체 Workflow를 하나의 Task로 다루는 엔진
- 연산자를 통해 더 유연한 방법으로 함수 조작 가능
- 수행 속도가 훨씬 빠르고 선택지가 넓음
- 장점
    - 연산 수행에 대한 리소스가 많이 필요할 경우 필요할 때만 수행
    - 모든 조인과 의존 관계를 명시적으로 선언하여 Locality를 줄임
    - 중간 상태를 디스크에 기록하여 가용성 업
    - 선행 상태를 기다리지 않고 수행
    - 새로운 연산 시 기존에 실행 중이던 JVM 사용

#### 내결함성

- 중간 상태를 사용하지 경우 -> 재계산
- 데이터 연산의 결정적 여부에 따라 재연산 여부를 고려

#### 구체화에 대한 논의

- 데이터 플로 엔진은 일부를 제외하고 파이프라인 실행 방식 가능
- 작업 완료 시 디스크 등에 기록
- 모든 중간 과정을 기록할 필요 X

### 그래프와 반복 처리

- 페이지 랭크 알고리즘 같이 간선을 순회하면서 찾는 방식
- 더 이상 따라갈 조건이 없을 때까지 반복하여 따라감 - <b>이형적 폐쇄</b>
- 완료할 때까지 반복이라는 로직은 아래 처럼 구현
    - 외부 스케쥴러가 일괄 처리 수행
    - 종료 조건 기반 완료 확인
    - 1번 재수행

#### 프리글 처리 모델

- 하나의 정점에서 다른 정점으로 메시지를 전달
    - Map-Reduce와의 차이점은 메모리 상태를 기억

#### 내결함성

- 메시지는 일괄 처리가 가능하여 통신 중 대기 시간 미발생
- 프리글 구현상 exactly-at-once 처리
- 대기 시간은 반복과 반복 사이에만 나옴
- 노드에 장애가 날 경우, 마지막 체크 포인트에서 연산 재식하는 것

#### 병렬 실행

- 어떤 장비에서 실행되는 지 알 필요 없음
- 결과적으로 장비 간 통신 오버헤드가 많이 발생
- 이에 따라 단일 장비 알고리즘이 분산 보다 성능이 좋을 가능성이 높음

### 고수준 API와 언어

- 직접 Map-Reduce 처리의 어려움
    - 고수준 언어나 API가 인기
- 이점
    - 코드를 적게 작성 가능
    - 대화식 사용 지원
    - 코드가 어떤식으로 작성하는 지 확인 가능
    - 사용자가 시스템을 생산성 있게 사용하고 장비 수준에서 작업이 효율화

#### 선언형 질의 언어로 전환

- 선언적으로 선언 시 질의 최적화기가 최적 방법 결정
- 이점
    - 출력에 필요한 코드를 임의로 실행해줌
    - 칼럼 기반 저장 레이아웃으로 최적화 가능
    - 캐시 히트률이 호출이 높아져서 함수 호출를 회피

#### 다양한 분야를 지원하기 위한 전문화

- 표준화 된 처리 패턴 때문에 재사용이 용이
- 광범위한 범위에서 필요한 알고리즘을 분산 수행 (k-nearest algorithm)
- MPP DB와 일괄 처리 엔진이 점점 비슷해지는 중