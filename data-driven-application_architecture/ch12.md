# ch12 데이터 시스템의 미래

- 신뢰할 수 있고 확장 가능하며 유지 보수 쉽게 만드는 방법을 탐구 하는 방법

## 데이터 통합

- 가장 적절한 도구를 선택하는 것은 상황에 따라 다름
    - 선택지가 많으면, 소프트웨어 제품과 환경 사이의 대응관계를 파악
    - 모든 환경 조건을 만족하는 소프트웨어는 없기 때문에, 다른 소프트웨어와 잘 묶어 사용 해야 함

### 파생 데이터에 특화된 도구의 결합

- OLTP DB는 특정 키워드 기반 쿼리를 추가 요구하는 것은 빈번하게 존재
    - PostgreSQL의 경우 간단한 DB를 만들기는 쉽지만 전문 탐색 도구가 필요
    - 역색인 검색 색인은 지속성 있는 레코딩 시스템으로 부적합하여 위 PostgreSQL과 결합하는 방식으로 사용하면 좋음
- 데이터 통합의 필요성은 전체 데이터 플로우를 고려해야 함

#### 데이터플로에 대한 추론

- 데이터 사본을 여러 저장소 시스템에 유지가 필요할 시 입력과 출력을 분명히 해야함
    - 데이터 초기 기록 위치, 원본에서 파생되는 데이터 표현형, 데이터가 올바른 장소로 올바른 형식으로 들어가는 지 충분히 고려해야 함
- 검색 색인이 이를 직접 기록하게 한다면, 문제가 발생 가능성이 높아짐
    - 파생 데이터 시스템은 이벤트 로그를 기반으로 갱신하면 결정적이고 멱등성을 지니고 복구가 쉬움

#### 파생 데이터 대 분산 트랜잭션

- 파생 데이터와 분산 트랜잭션의 차이
    - 트랜잭션 시스템은 일반적으로 *선형성*을 지원
    - 파생 데이터 시스템은 대개 비동기로 갱신되어 동시간 갱신 보장을 미지원
- 로그 기반 파생 데이터가 좋은 접근성
    - XA는 결함 대응에 취약 및 성능이 안 좋음
- **최종적 일관성**을 어떻게 다루는 지가 중요

#### 전체 순서화의 제약

- 작은 시스템에서 이벤트 로그 순서 전체를 보장이 가능하지만 규모가 커지만 한계 등장
    - 모든 이벤트가 **단일 노드 리더**로 통하지 않으면 규모가 커지면 복수의 장비로 파티션 필요 -> 이벤트 순서 애매
    - 지역적 분산 데이터센터는 독립적 리더를 두어야 함
    - 마이크로 서비스는 서비스 간 상태는 비공유
    - 클라이언트는 서버의 응답을 기다리지 않고 지속 갱신
- 이벤트 전체 순서를 정하는 것은 **전체 순서 브로드캐스트** 라고 지칭
    - 합의와 동등하지만 아직 미해결 연구 과제

#### 인과성 획득을 위한 이벤트 순서화

- 이벤트 간 인과성이 없는 경우에는 순서가 정해지지 않아도 문제 X
- SNS 기준 친구 끊기와 메시지 보내기는 의존성 X
    - 다만 조인의 타이밍만 문제와 관련
    - 논리적 타임 스탬프를 사용할 경우 전체 순서화를 지원
    - 시스템 상태를 기록하는 이벤트를 로깅할 수 있고 식별자를 참조할 수 있음
    - 충돌 해소 알고리즘은 예상치 못한 순서로 전송된 이벤트를 처리하는 데 도움을 줌

### 일괄 처리와 스트림 처리

- 데이터 통합의 목표는 데이터를 올바른 장소에 올바른 형태로 두는 것
- 일괄 처리와 스트림 처리의 출력은 파생 데이터 셋
- 두 처리 간의 여러 공통 원리가 있지만, 스트림 처리는 끝이 없는 데이터셋 운영, 일괄 처리는 유한한 크기를 처리
- 스파크는 일괄 처리 엔진 상에서 스트림 처리, 스트림을 마이크로 일괄 처리 단위로 나누어 처리
    - 아파치 플링크는 스트림 처리 엔진 상에서 일괄 처리 수행

#### 파생상태 유지

- 일괄 처리는 함수 프로그래밍 언어로 코드를 사용하지 않아도 강력한 함수형 특징을 지님
    - 일괄 처리는 결정적이고, 출력이 입력에만 의존하며 순수 함수 장려
    - 스트림 처리도 유사하지만, 연산자 확장해서 상태 관리가능 하면 내결함성을 지님
- 입출력을 잘 정의한 결정적 함수는 내결함성에 도움이 될 뿐 아니라 조직 내 데이터 플로 추론을 단순화
    - 데이터 파이프라인의 관점에서 생각하는 것이 좋음
    - 데이터 파이프라인은 함수형 코드를 통해 상태 변화를 밀어 넣고 결과를 파생 시스템에 적용
- 이론 상으로 파생 데이터 시스템은 트랜잭션 내 보조 색인을 동기식으로 갱신하여 동기식 처럼 운영 가능
    - 비동기 방식은 이벤트 기반 로그 시스템을 견고하게 만듬
    - 분산 트랜잭션은 장비 일부 실패 시 abort하기 때문에 실패가 증폭되는 경향이 있음
- 보조 색인을 가진 파티셔닝 시스템이 색인을 용어 기준으로 파티셔닝 시 복수 파티셔닝에 요청을 보내야 함
    - 문서 기준이면 모든 파티션에 보내야 함
    - 비동기 방식이면 이런 통신을 신뢰성있고 확장성이 좋게 유지 가능

#### 애플리케이션 발전을 위한 데이터 재처리

- 파생 데이터를 유지할 때 일괄 처리와 스트림 처리는 상당히 유용
    - 스트림 처리 시 입력의 변화를 빠르게 파생 뷰 반영 가능
    - 일괄 처리 사용시 누적된 상당량의 과거를 처리해서 파생뷰를 만들기 가능
- 기존 데이터를 재처리하는 것은 시스템을 유지보수하여, 기능 추가와 변경 요구 사항에 대응하기 위함
- 파생 뷰 사용 시 점진적 발전 가능
    - 기존 뷰와 새 뷰의 비율 조정을 통해 기존 뷰를 내리는 방식
- 점진적 이전은 오처리 시 원복 가능하여 시스템을 빠르게 개선 가능

#### 람다 아키텍처

- 일괄 처리는 과거 데이터 처리, 스트림처리는 최근 갱신 데이터 처리 이를 합친 것이 **람다 아키텍처**
- 입력 데이터를 분변 이벤트로서 증가하기만 하는 데이터 셋에 기록하는 방법 - 이벤트 소싱과 유사
    - 하둡 맵리듀스와 같은 일괄 처리 시스템과 스톰 같은 스트림 시스템을 같이 운용
- 람다 아키텍처 접근 법에서 이벤트를 소비해서 빠르게 뷰에 반영, 이후 일괄 처리자가 같은 이벤트 집합을 소비해서 정확한 파생 뷰 반영
    - 일괄 처리는 버그가 적고 간단 그러나 느리고 정확한 알고리즘
    - 스트림 처리는 신뢰성이 떨어지고 내결함성 확보의 어려움 그러나 빠른 근사 알고리즘
- 람다 아키텍처는 불변 이벤트 스트림에 대한 뷰를 파생하고 필요할 때 이벤트를 재처리하는 원리 제공
- 람다 아키텍처의 문제점
    - 일괄 처리와 스트림 처리 모두 같은 로직 유지 필요
    - 스트림 파이프라인과 일괄 처리 파이프 라인은 분리된 출력 생산
    - 과거 데이터를 재처리할 수 있으나 비용이 큼

#### 일괄 처리와 스트림 처리의 통합

- 일괄 처리와 스트림 연산을 모두 구현하여 장점만 취할 수 있는 작업을 위해 아래 기능 필요
    - 이벤트 스트림 내에 과거 이벤트를 재생하는 능력 존재
    - 스트림 처리자에서 사용되는 exactly at once 시맨틱
    - 이벤트 시간 기준으로 윈도를 처리하는 도구

## 데이터베이스 언번들링

- 추상화 수준에서 하둡, DB는 같은 기능 수행
    - 데아터를 저장하고 처리하며 질의 수행
    - 데이터 모델의 레코드로 데이터 저장
    - 운영 체제는 데이터를 파일로써 파일 시스템에 저장
- 운영 체제와 DB의 유사점과 차이점은 탐구할 가치가 존재
- 유닉스와 관계형 DB는 다른 철학으로 접근
    - OS는 논리적이지만 하드웨어 추상화를 프로그래머에게 제공
    - 관계형 데이터베이스는 디스크 상의 복잡성을 감추는 고수준 추상화 제공

### 데이터 저장소 기술 구성하기

- 데이터베이스가 사용하는 기능
    - 보조 색인은 필드 값을 기반으로 레코드를 효율적으로 검색할 수 있는 기능
    - 구체화 뷰는 질의 결과를 미리 연산한 캐시의 일종
    - 복제 로그는 복사본을 다르 로드에 최신 상태에 유진하는 기능
    - 전문 검색 색인은 텍스트에서 키워드 검색을 가능하게 하는 기능

#### 색인 생성하기

- 데이터베이스는 일관된 스냅샷을 사용해서 색인할 필드 값을 모두 골라 정렬하고 색인에 기록
    - 일관된 스냅샷을 만든 이후에 실행된 쓰기의 백로그를 처리해야 함
- CREATE INDEX를 실행할 때마다 기존 데이터셋을 재처리해서 기존 데이터를 반영하는 새로운 뷰로서 색인을 파생

#### 모든 것의 메타데이터베이스

- 일종의 전체 조직의 데이터플로가 거대한 데이터베이스처럼 볼 수 있음
- 일괄 처리와 스트림 처리자는 트리거와 스토어드 프로시저 및 구체화 뷰 유지 루틴을 정교하게 구현한 것과 같음

##### 연합 데이터 베이스 : 읽기를 통합

- 엄청나게 많은 하단 저장소 엔진과 처리 메서드를 통합해 질의하는 인터페이스 제공

##### 언번들링 데이터베이스 : 쓰기를 통합

- 연합 데이터 베이스는 쓰기를 동기화하기에는 적합하지 않은 해결책
- 저장소 시스템을 신뢰성 있게 결합하기 쉽게 만드는 것은 데이터베이스 색인 유지 기능을 다른 기술에 걸친 쓰기를 동기화 하는 방식으로 언번들링 하는 방식과 유사
 
#### 언번들링이 동작하게 만들기

- 다양한 구성 요소로부터 신뢰할 수 있고 확장 가능하며 유지보수 하기 쉬운 시스템을 만드는 측면에서 연합과 언번들링은 반대의 위치
- 쓰기를 동기화 하는 기존 접근 법은 분산 트랜잭션 요구
    - 데이터가 이종 기술간 이동하는 케이스는 비동기 이벤트 로그를 사용하는 편이 강력하고 현실적
- 분산 트랜잭션은 특정 스트림 처리자 내에서 exactly at once를 사용하기 위해 사용
- 로그 기반 통합은 loose coupling이 가장 큰 장점
    - 비동기 이벤트 스트림을 사용 시 일부 구성에 장애가 발생해도 나머지 시스템은 정상 동작
    - 인적 수준에서 데이터 시스템을 언번들링 시 각 구성 요소와 서비스를 서로 다른 팀에서 개발 및 유지보수 가능

#### 언번들링 대 통합 시스템

- 언번들링은 DB를 대체하지는 못함
    - DB는 스트림 처리자 상태를 유지하기 위해 필요하고 일괄 처리 및 출력 질의를 처리하기 위해서도 필요
- 여러 다른 인프라에서 수행하는 복잡성 또한 문제가 될 가능성 존재
    - 동적 부분을 가능한 적제 처리해야 함
- 언번들링의 목표는 성능 측면에서 DB와 경쟁하는 것이 아닌, 더 넓은 범위의 작업 부하에 대해 좋은 성능을 달성하기 위함

#### 뭐가 빠졌지?

- 유닉스 셀과 동일한 언번들링 DB는 존재하지 않음
- 캐시를 사전 계산하고 더 쉽게 갱신 할 수 있으면 좋을 것으로 예상 - 구체화 뷰가 그 예시

### 데이터플로 주변 애플리케이션 설계

- 언번들링 데이터베이스 접근법은 *데이터베이스 인사이드 아웃*이라고도 명명
- 현대 데이터 시스템은 내결함성과 확장성이 있어야 하고 지속성 있게 데이터를 저장
    - 데이터 시스템은 시간의 흐름에 따라 다른 그룹 사람들이 개발한 이종 기술과도 통합이 가능해야 하며, 이미 존재하는 라이브러리를 재사용 해야함

#### 파생 함수로서의 애플리케이션 코드

- 데이터셋이 다른 데이터셋으로부터 파생될 때는 변환 함수 몇 가지를 거침
    - 예시
        - 보조 색인은 단순한 변환 함수를 사용하는 파생 데이터셋 일종
        - 전문 검색은 다양한 자연어 처리 함수를 적용한 효율적인 조회로 자료 구축
- 보조 색인용 파생 함수는 일반적인 요구 사항이라 데이터베이스에 핵심 기능으로 내장 되어 있음
- 파생 데이터셋을 생성하는 함수가 표준 함수가 아니라면 사용자 정의 코드를 써서 어플리케이션에 특화되도록 처리 필요
    - 트리거, 스토어드 프로시저 등등

#### 애플리케이션 코드와 상태 분리

- 이론상 데이터베이스가 운영 체제와 같이 임의의 어플리케이션 코드를 배포하는 환경이 가능하나 비현실적
- 배포와 클러스터 관리 도구는 어플리케이션 코드를 수행하는 목적으로 설계
    - 이런 도구는 데이터 베이스의 많은 기능 중 하나로 사용자 정의 함수 실행 보다 나음
- 일부는 지속성 있는 데이터 저장을, 일부는 애플리케이션 코드 실행을 전문으로 하지만 두 가지는 상호작용 가능
- 오늘날 웹 어플리케이션은 stateless 상태로 배포
    - 사용자 요청은 어떤 서버로도 route 가능
    - state 관리와 어플리케이션 로직을 분리
- 전형적인 웹 어플리케이션 모델에서는 네트워크를 통해 동기식으로 접근 할 수 있는 변경 가능한 공유 변수와 같이 동작
- 그러나 대부분은 이에 대한 변경을 감지 하지 못함으로 옵저버 패턴으로 구현할 수 있음 (내장 기능으로 지원 X)
- 따라서 데이터베이스에 대해 폴링을 반복하는 게 유일한 방법

#### 데이터플로: 상태 변경과 애플리케이션 코드 간 상호 작용

- 데이터 플로 측면에서 어플리케이션을 생각하는 것은 코드와 state간의 관계를 재조정하는 것
    - DB를 직접 조작하는 대신, 상태 변경 및 이를 처리하는 코드에 대해 숙고해야 함
- 데이터베이스의 변경 로그를 구독 가능한 이벤트 스트림으로 취급
    - 튜플 공간 모델에서 상태 변화를 관찰에 분산 연산으로 표현하는 방법 탐구
- 데이터베이스에서 데이터 변경으로 트리거가 발생하거나 보조 색인을 갱신할 때 비슷한 일이 발생
    - 데이터베이스를 언번들링한다는 것은 이 아이디어를 통해 원본 데이터베이스 외부에 파생 데이터셋을 생성할 때 적용
- 파생 데이터 유지는 비동기 작업 실행과는 다름
    - 파생 데이터 유지시 상태 변경 순서는 중요
    - 내결함성은 파생 데이터의 핵심
- 안정적인 메시지 순서화와 내결함성 메시지 처리는 상당히 엄격한 요구 사항이지만 분산 트랜잭션 보다 저렴하면서 탄탄한 운영을 제공
    - 최신 스트림 처리자는 대규모로 순서화와 신뢰성 보장 제공
    - 스트림 처리자에서 어플리케이션 코드를 스트림 연산자로 실행 가능
- 어플리케이션 코드로 데이터베이스에 내장된 파생 함수가 일반적으로 지원하지 않는 임의 처리가 가능
    - 파이프로 연결된 유닉스 도구와 같이 스트림 처리자를 구성해서 데이터 플로를 중심으로 대형 시스템 구축 가능

#### 스트림 처리자와 서비스

- 최근 유행하는 개발 스타일은 Rest Api 같은 동기 네트워크 요청을 통해 통신하는 서비스 집합으로 나누는 것
    - 일체식 어플리케이션에 비해 느슨한 연결을 통한 조직적 확장성을 가짐
- 스트림 연산자로 Dataflow 시스템을 구성하는 것은 MicroService와 유사한 특징이 많음
    - 다만 통신 매커니즘이 다름
- 향상된 내결함성 등 장점 외에도 데이터플로 시스템은 성능적으로 매우 뛰어남
- 변경 스트림 구독은 필요할 떄 현재 상태를 조회하는 것 보다, 스프레드시스템 연산 모델에 가까움
    - 일부 데이터 변경이 있을 때맏, 파생 데이터가 신속하게 갱신

### 파생 상태 관찰하기

- 추상적인 수준에서 데이터플로 시스템은 파생 데이터 셋을 생성하고 최신 상태를 유지하는 데에 사용할 수 있으며, 이 과정을 **쓰기 경로**라 명명
- 시스템에 정보를 기록할 때마다 일괄 처리와 스트림 처리의 여러 단계를 거친 다음 결과정으로 모든 파생 데이터셋에 통합 갱신
- 파생 데이터 생성의 이유는 질의이며 이를 **읽기 경로**라고 명명
    - 사용자 요청을 할 떄 파생 데이터 셋을 읽고 가공하여 사용자 응답 제공
- 파생 데이터셋은 쓰기 경로와 읽기 경로가 만는 장소
    - 따라서 쓰기 시간에 필요한 작업의 양과 읽기 시간에 필요한 시간의 트레이드 오프

#### 구체화 뷰와 캐싱

- 전문 검색 색인은 좋은 예제
    - 키워드에서 AND나 OR 등의 논리 연산 추가
- 색인이 존재하지 않으면, 모든 문서 스캔 필요
    - 쓰기 경로 부담은 없지만 읽기 경로가 기하급수적 증가
- 모든 질의의 검색 결과를 캐싱해놓으면, 작업량이 줄어들지만 이는 비현실적
- 가장 공통 질의만 캐싱하는 방법이 있음
    - 이를 **공통 질의 캐시**

#### 오프라인 대응 가능한 상태 저장 클라이언트

- 과거와 달리 각 기기 모두 로컬 장치에 저장할 수 있어 모두 처리할 때 서버까지 반복할 필요 X
- 동기식 네트워크 요청을 반드시 처리하지 않는 **offline-first** 어플리케이션이 각광을 받음
- 클라이언트에서 상태를 유지하는 쪽으로 나아가면 새로운 기회가 옴

#### 상태 변경을 클라이언트에게 푸시하기

- 변경 사항을 폴링하지 않으면 신선도가 떨어지는 캐시
- 최신 프로토콜들이 HTTP의 기본적인 req/res 요청 패턴을 벗어남
    - 서버 전송 이벤트와 웹 소켓은 TCP 접속을 유지하면서 주도적으로 서버가 메시지를 브라우저에 보내는 통신 방식
    - 로컬의 저장된 상태가 변경되었을 때 서버에서 주도적으로 클라이언트가 신선도가 떨어지는 것을 방지
- 로그 기반 메시지 브로커를 통해 알림 전파 가능

#### 종단 간 스트림

- React, Flux, Redux 같은 상태 저장 클라이언트와 사용자 인터페이스 개발용 도구는 사용자 입력을 표현하는 이벤트 스트림 혹은 서버 응답 스트림을 구독하는 방식을 사용해 클라이언ㅇ트 상태 관리
    - 이벤트 소싱과 비슷
- 상태 변경은 종단 간 쓰기 경로에 따라 흐를 수 있음
    - 상호작용을 통해 이벤트 로그를 거쳐 파생 데이터 시스템과 스트림 처리자를 통해 다른 장치의 상태를 보고 있는 사용자 인터페이스까지 이어짐
- 쓰기 경로를 최종 사용자까지 확장하려면 근본적으로 시스템 재구축 필요
    - req/res 방식에서 벗어나 pub/sub Dataflow 방식으로 변경 필요
    - 데이터 시스템을 설계 한다면 현재 상태를 질의하는 방식이 아니라 변경 사항을 구독하는 방식으로 처리 필요

#### 읽기도 이벤트다

- 스트림 처리자가 파생 데이터를 저장소에 기록하거나 질의 요청을 할 때 읽기 경로와 쓰기 경로 사이의 경계 작동
    - 저장소는 임의 접근 읽기 질의가 가능
- 읽기는 질의 대상 데이터가 저장된 노드로 직접 보내는 일시적 네트워크 요청
    - 읽기 요청을 이벤트 스트림으로 표현하고, 읽기 이벤트와 쓰기 이벤트 모두를 스트림 처리자로 보내는 방법 또한 가능
- 쓰기와 읽기 모두 이벤트로 표현하고 처리하는 것은 스트림 테이블 조인 수행과 동일
- 일회성 읽기 요청은 조인 연산자를 통해 흘러가고 이후에 즉시 사라짐
    - 구독 요청은 과거, 미래 이벤트와의 영속적 조인
- 읽기 이벤트 로그를 기록하면, 인과적 의존성과 시스템 전체의 데이터 출처를 추적 가능
- 지속성 있는 저장소에 읽기 이벤트를 입력하면 추적하기 좋지만 I/O 비용 발 생 및 추가 저장소 필요

#### 다중 파티션 데이터 처리

- 스트림 처리자가 제공하는 메시지 라우팅 및 조인용 인프라를 이용하면 여러 파티션의 데이터 통합이 필요한 복잡한 질의를 분산 실행 할 수 있는 가능성 오픈
- 스톰 분산 RPC 기능이 이런 사용 패턴 지원
- 질의를 스트림으로 간주할 경우 대규모 어플리케이션 구현하는 방법이 생김

## 정확성을 목표로

### 데이터베이스에 관한 종단 간 논증

#### 연산자의 정확히 한 번 실행
#### 중복 억제
#### 연산 식별자
#### 종단 간 논증
#### 종단 간 사고를 데이터 시스템에 적용하기

### 제약조건 강제하기

#### 유일성 제약 조건은 합의가 필요하다
#### 로그 기반 메시징의 유일성
#### 다중 파티션 요청 러리

### 적시성과 무결성

#### 데이터 플로 시스템의 정확성
#### 느슨하게 해석되는 제약 조건
#### 코디네이션 회피 데이터 시스템

### 믿어라 하지만 확인하라

#### 소프트웨어 버그가 발생해도 무결성 유지하기
#### 약속을 맹목적으로 믿지 마라
#### 검증하는 문화
#### 감사 기능 설계
#### 다시 종단 간 논증
#### 감사 데이터 시스템용 도구

## 옳은 일 하기

### 예측 분석

#### 편견과 차별
#### 책임과 의무
#### 피드백 루프

### 사생활과 추적

#### 동의와 선택의 자유
#### 사생활과 데이터 사용
#### 자산과 권력으로서의 데이터
#### 산업 혁명의 기억
#### 법률과 자기 규제