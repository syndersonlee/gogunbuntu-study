# ch12 데이터 시스템의 미래

- 신뢰할 수 있고 확장 가능하며 유지 보수 쉽게 만드는 방법을 탐구 하는 방법

## 데이터 통합

- 가장 적절한 도구를 선택하는 것은 상황에 따라 다름
    - 선택지가 많으면, 소프트웨어 제품과 환경 사이의 대응관계를 파악
    - 모든 환경 조건을 만족하는 소프트웨어는 없기 때문에, 다른 소프트웨어와 잘 묶어 사용 해야 함

### 파생 데이터에 특화된 도구의 결합

- OLTP DB는 특정 키워드 기반 쿼리를 추가 요구하는 것은 빈번하게 존재
    - PostgreSQL의 경우 간단한 DB를 만들기는 쉽지만 전문 탐색 도구가 필요
    - 역색인 검색 색인은 지속성 있는 레코딩 시스템으로 부적합하여 위 PostgreSQL과 결합하는 방식으로 사용하면 좋음
- 데이터 통합의 필요성은 전체 데이터 플로우를 고려해야 함

#### 데이터플로에 대한 추론

- 데이터 사본을 여러 저장소 시스템에 유지가 필요할 시 입력과 출력을 분명히 해야함
    - 데이터 초기 기록 위치, 원본에서 파생되는 데이터 표현형, 데이터가 올바른 장소로 올바른 형식으로 들어가는 지 충분히 고려해야 함
- 검색 색인이 이를 직접 기록하게 한다면, 문제가 발생 가능성이 높아짐
    - 파생 데이터 시스템은 이벤트 로그를 기반으로 갱신하면 결정적이고 멱등성을 지니고 복구가 쉬움

#### 파생 데이터 대 분산 트랜잭션

- 파생 데이터와 분산 트랜잭션의 차이
    - 트랜잭션 시스템은 일반적으로 *선형성*을 지원
    - 파생 데이터 시스템은 대개 비동기로 갱신되어 동시간 갱신 보장을 미지원
- 로그 기반 파생 데이터가 좋은 접근성
    - XA는 결함 대응에 취약 및 성능이 안 좋음
- **최종적 일관성**을 어떻게 다루는 지가 중요

#### 전체 순서화의 제약

- 작은 시스템에서 이벤트 로그 순서 전체를 보장이 가능하지만 규모가 커지만 한계 등장
    - 모든 이벤트가 **단일 노드 리더**로 통하지 않으면 규모가 커지면 복수의 장비로 파티션 필요 -> 이벤트 순서 애매
    - 지역적 분산 데이터센터는 독립적 리더를 두어야 함
    - 마이크로 서비스는 서비스 간 상태는 비공유
    - 클라이언트는 서버의 응답을 기다리지 않고 지속 갱신
- 이벤트 전체 순서를 정하는 것은 **전체 순서 브로드캐스트** 라고 지칭
    - 합의와 동등하지만 아직 미해결 연구 과제

#### 인과성 획득을 위한 이벤트 순서화

- 이벤트 간 인과성이 없는 경우에는 순서가 정해지지 않아도 문제 X
- SNS 기준 친구 끊기와 메시지 보내기는 의존성 X
    - 다만 조인의 타이밍만 문제와 관련
    - 논리적 타임 스탬프를 사용할 경우 전체 순서화를 지원
    - 시스템 상태를 기록하는 이벤트를 로깅할 수 있고 식별자를 참조할 수 있음
    - 충돌 해소 알고리즘은 예상치 못한 순서로 전송된 이벤트를 처리하는 데 도움을 줌

### 일괄 처리와 스트림 처리

- 데이터 통합의 목표는 데이터를 올바른 장소에 올바른 형태로 두는 것
- 일괄 처리와 스트림 처리의 출력은 파생 데이터 셋
- 두 처리 간의 여러 공통 원리가 있지만, 스트림 처리는 끝이 없는 데이터셋 운영, 일괄 처리는 유한한 크기를 처리
- 스파크는 일괄 처리 엔진 상에서 스트림 처리, 스트림을 마이크로 일괄 처리 단위로 나누어 처리
    - 아파치 플링크는 스트림 처리 엔진 상에서 일괄 처리 수행

#### 파생상태 유지

- 일괄 처리는 함수 프로그래밍 언어로 코드를 사용하지 않아도 강력한 함수형 특징을 지님
    - 일괄 처리는 결정적이고, 출력이 입력에만 의존하며 순수 함수 장려
    - 스트림 처리도 유사하지만, 연산자 확장해서 상태 관리가능 하면 내결함성을 지님
- 입출력을 잘 정의한 결정적 함수는 내결함성에 도움이 될 뿐 아니라 조직 내 데이터 플로 추론을 단순화
    - 데이터 파이프라인의 관점에서 생각하는 것이 좋음
    - 데이터 파이프라인은 함수형 코드를 통해 상태 변화를 밀어 넣고 결과를 파생 시스템에 적용
- 이론 상으로 파생 데이터 시스템은 트랜잭션 내 보조 색인을 동기식으로 갱신하여 동기식 처럼 운영 가능
    - 비동기 방식은 이벤트 기반 로그 시스템을 견고하게 만듬
    - 분산 트랜잭션은 장비 일부 실패 시 abort하기 때문에 실패가 증폭되는 경향이 있음
- 보조 색인을 가진 파티셔닝 시스템이 색인을 용어 기준으로 파티셔닝 시 복수 파티셔닝에 요청을 보내야 함
    - 문서 기준이면 모든 파티션에 보내야 함
    - 비동기 방식이면 이런 통신을 신뢰성있고 확장성이 좋게 유지 가능

#### 애플리케이션 발전을 위한 데이터 재처리

- 파생 데이터를 유지할 때 일괄 처리와 스트림 처리는 상당히 유용
    - 스트림 처리 시 입력의 변화를 빠르게 파생 뷰 반영 가능
    - 일괄 처리 사용시 누적된 상당량의 과거를 처리해서 파생뷰를 만들기 가능
- 기존 데이터를 재처리하는 것은 시스템을 유지보수하여, 기능 추가와 변경 요구 사항에 대응하기 위함
- 파생 뷰 사용 시 점진적 발전 가능
    - 기존 뷰와 새 뷰의 비율 조정을 통해 기존 뷰를 내리는 방식
- 점진적 이전은 오처리 시 원복 가능하여 시스템을 빠르게 개선 가능

#### 람다 아키텍처

- 일괄 처리는 과거 데이터 처리, 스트림처리는 최근 갱신 데이터 처리 이를 합친 것이 **람다 아키텍처**
- 입력 데이터를 분변 이벤트로서 증가하기만 하는 데이터 셋에 기록하는 방법 - 이벤트 소싱과 유사
    - 하둡 맵리듀스와 같은 일괄 처리 시스템과 스톰 같은 스트림 시스템을 같이 운용
- 람다 아키텍처 접근 법에서 이벤트를 소비해서 빠르게 뷰에 반영, 이후 일괄 처리자가 같은 이벤트 집합을 소비해서 정확한 파생 뷰 반영
    - 일괄 처리는 버그가 적고 간단 그러나 느리고 정확한 알고리즘
    - 스트림 처리는 신뢰성이 떨어지고 내결함성 확보의 어려움 그러나 빠른 근사 알고리즘
- 람다 아키텍처는 불변 이벤트 스트림에 대한 뷰를 파생하고 필요할 때 이벤트를 재처리하는 원리 제공
- 람다 아키텍처의 문제점
    - 일괄 처리와 스트림 처리 모두 같은 로직 유지 필요
    - 스트림 파이프라인과 일괄 처리 파이프 라인은 분리된 출력 생산
    - 과거 데이터를 재처리할 수 있으나 비용이 큼

#### 일괄 처리와 스트림 처리의 통합

- 일괄 처리와 스트림 연산을 모두 구현하여 장점만 취할 수 있는 작업을 위해 아래 기능 필요
    - 이벤트 스트림 내에 과거 이벤트를 재생하는 능력 존재
    - 스트림 처리자에서 사용되는 exactly at once 시맨틱
    - 이벤트 시간 기준으로 윈도를 처리하는 도구

## 데이터베이스 언번들링

- 추상화 수준에서 하둡, DB는 같은 기능 수행
    - 데아터를 저장하고 처리하며 질의 수행
    - 데이터 모델의 레코드로 데이터 저장
    - 운영 체제는 데이터를 파일로써 파일 시스템에 저장
- 운영 체제와 DB의 유사점과 차이점은 탐구할 가치가 존재
- 유닉스와 관계형 DB는 다른 철학으로 접근
    - OS는 논리적이지만 하드웨어 추상화를 프로그래머에게 제공
    - 관계형 데이터베이스는 디스크 상의 복잡성을 감추는 고수준 추상화 제공

### 데이터 저장소 기술 구성하기

- 데이터베이스가 사용하는 기능
    - 보조 색인은 필드 값을 기반으로 레코드를 효율적으로 검색할 수 있는 기능
    - 구체화 뷰는 질의 결과를 미리 연산한 캐시의 일종
    - 복제 로그는 복사본을 다르 로드에 최신 상태에 유진하는 기능
    - 전문 검색 색인은 텍스트에서 키워드 검색을 가능하게 하는 기능

#### 색인 생성하기

- 데이터베이스는 일관된 스냅샷을 사용해서 색인할 필드 값을 모두 골라 정렬하고 색인에 기록
    - 일관된 스냅샷을 만든 이후에 실행된 쓰기의 백로그를 처리해야 함
- CREATE INDEX를 실행할 때마다 기존 데이터셋을 재처리해서 기존 데이터를 반영하는 새로운 뷰로서 색인을 파생

#### 모든 것의 메타데이터베이스

- 일종의 전체 조직의 데이터플로가 거대한 데이터베이스처럼 볼 수 있음
- 일괄 처리와 스트림 처리자는 트리거와 스토어드 프로시저 및 구체화 뷰 유지 루틴을 정교하게 구현한 것과 같음

##### 연합 데이터 베이스 : 읽기를 통합

- 엄청나게 많은 하단 저장소 엔진과 처리 메서드를 통합해 질의하는 인터페이스 제공

##### 언번들링 데이터베이스 : 쓰기를 통합

- 연합 데이터 베이스는 쓰기를 동기화하기에는 적합하지 않은 해결책
- 저장소 시스템을 신뢰성 있게 결합하기 쉽게 만드는 것은 데이터베이스 색인 유지 기능을 다른 기술에 걸친 쓰기를 동기화 하는 방식으로 언번들링 하는 방식과 유사
 
#### 언번들링이 동작하게 만들기

- 다양한 구성 요소로부터 신뢰할 수 있고 확장 가능하며 유지보수 하기 쉬운 시스템을 만드는 측면에서 연합과 언번들링은 반대의 위치
- 쓰기를 동기화 하는 기존 접근 법은 분산 트랜잭션 요구
    - 데이터가 이종 기술간 이동하는 케이스는 비동기 이벤트 로그를 사용하는 편이 강력하고 현실적
- 분산 트랜잭션은 특정 스트림 처리자 내에서 exactly at once를 사용하기 위해 사용
- 로그 기반 통합은 loose coupling이 가장 큰 장점
    - 비동기 이벤트 스트림을 사용 시 일부 구성에 장애가 발생해도 나머지 시스템은 정상 동작
    - 인적 수준에서 데이터 시스템을 언번들링 시 각 구성 요소와 서비스를 서로 다른 팀에서 개발 및 유지보수 가능

#### 언번들링 대 통합 시스템

- 언번들링은 DB를 대체하지는 못함
    - DB는 스트림 처리자 상태를 유지하기 위해 필요하고 일괄 처리 및 출력 질의를 처리하기 위해서도 필요
- 여러 다른 인프라에서 수행하는 복잡성 또한 문제가 될 가능성 존재
    - 동적 부분을 가능한 적제 처리해야 함
- 언번들링의 목표는 성능 측면에서 DB와 경쟁하는 것이 아닌, 더 넓은 범위의 작업 부하에 대해 좋은 성능을 달성하기 위함

#### 뭐가 빠졌지?

- 유닉스 셀과 동일한 언번들링 DB는 존재하지 않음
- 캐시를 사전 계산하고 더 쉽게 갱신 할 수 있으면 좋을 것으로 예상 - 구체화 뷰가 그 예시

### 데이터플로 주변 애플리케이션 설계

- 언번들링 데이터베이스 접근법은 *데이터베이스 인사이드 아웃*이라고도 명명
- 현대 데이터 시스템은 내결함성과 확장성이 있어야 하고 지속성 있게 데이터를 저장
    - 데이터 시스템은 시간의 흐름에 따라 다른 그룹 사람들이 개발한 이종 기술과도 통합이 가능해야 하며, 이미 존재하는 라이브러리를 재사용 해야함

#### 파생 함수로서의 애플리케이션 코드

- 데이터셋이 다른 데이터셋으로부터 파생될 때는 변환 함수 몇 가지를 거침
    - 예시
        - 보조 색인은 단순한 변환 함수를 사용하는 파생 데이터셋 일종
        - 전문 검색은 다양한 자연어 처리 함수를 적용한 효율적인 조회로 자료 구축
- 보조 색인용 파생 함수는 일반적인 요구 사항이라 데이터베이스에 핵심 기능으로 내장 되어 있음
- 파생 데이터셋을 생성하는 함수가 표준 함수가 아니라면 사용자 정의 코드를 써서 어플리케이션에 특화되도록 처리 필요
    - 트리거, 스토어드 프로시저 등등

#### 애플리케이션 코드와 상태 분리

- 이론상 데이터베이스가 운영 체제와 같이 임의의 어플리케이션 코드를 배포하는 환경이 가능하나 비현실적
- 배포와 클러스터 관리 도구는 어플리케이션 코드를 수행하는 목적으로 설계
    - 이런 도구는 데이터 베이스의 많은 기능 중 하나로 사용자 정의 함수 실행 보다 나음
- 일부는 지속성 있는 데이터 저장을, 일부는 애플리케이션 코드 실행을 전문으로 하지만 두 가지는 상호작용 가능
- 오늘날 웹 어플리케이션은 stateless 상태로 배포
    - 사용자 요청은 어떤 서버로도 route 가능
    - state 관리와 어플리케이션 로직을 분리
- 전형적인 웹 어플리케이션 모델에서는 네트워크를 통해 동기식으로 접근 할 수 있는 변경 가능한 공유 변수와 같이 동작
- 그러나 대부분은 이에 대한 변경을 감지 하지 못함으로 옵저버 패턴으로 구현할 수 있음 (내장 기능으로 지원 X)
- 따라서 데이터베이스에 대해 폴링을 반복하는 게 유일한 방법

#### 데이터플로: 상태 변경과 애플리케이션 코드 간 상호 작용

- 데이터 플로 측면에서 어플리케이션을 생각하는 것은 코드와 state간의 관계를 재조정하는 것
    - DB를 직접 조작하는 대신, 상태 변경 및 이를 처리하는 코드에 대해 숙고해야 함
- 데이터베이스의 변경 로그를 구독 가능한 이벤트 스트림으로 취급
    - 튜플 공간 모델에서 상태 변화를 관찰에 분산 연산으로 표현하는 방법 탐구
- 데이터베이스에서 데이터 변경으로 트리거가 발생하거나 보조 색인을 갱신할 때 비슷한 일이 발생
    - 데이터베이스를 언번들링한다는 것은 이 아이디어를 통해 원본 데이터베이스 외부에 파생 데이터셋을 생성할 때 적용
- 파생 데이터 유지는 비동기 작업 실행과는 다름
    - 파생 데이터 유지시 상태 변경 순서는 중요
    - 내결함성은 파생 데이터의 핵심
- 안정적인 메시지 순서화와 내결함성 메시지 처리는 상당히 엄격한 요구 사항이지만 분산 트랜잭션 보다 저렴하면서 탄탄한 운영을 제공
    - 최신 스트림 처리자는 대규모로 순서화와 신뢰성 보장 제공
    - 스트림 처리자에서 어플리케이션 코드를 스트림 연산자로 실행 가능
- 어플리케이션 코드로 데이터베이스에 내장된 파생 함수가 일반적으로 지원하지 않는 임의 처리가 가능
    - 파이프로 연결된 유닉스 도구와 같이 스트림 처리자를 구성해서 데이터 플로를 중심으로 대형 시스템 구축 가능

#### 스트림 처리자와 서비스

- 최근 유행하는 개발 스타일은 Rest Api 같은 동기 네트워크 요청을 통해 통신하는 서비스 집합으로 나누는 것
    - 일체식 어플리케이션에 비해 느슨한 연결을 통한 조직적 확장성을 가짐
- 스트림 연산자로 Dataflow 시스템을 구성하는 것은 MicroService와 유사한 특징이 많음
    - 다만 통신 매커니즘이 다름
- 향상된 내결함성 등 장점 외에도 데이터플로 시스템은 성능적으로 매우 뛰어남
- 변경 스트림 구독은 필요할 떄 현재 상태를 조회하는 것 보다, 스프레드시스템 연산 모델에 가까움
    - 일부 데이터 변경이 있을 때맏, 파생 데이터가 신속하게 갱신

### 파생 상태 관찰하기

- 추상적인 수준에서 데이터플로 시스템은 파생 데이터 셋을 생성하고 최신 상태를 유지하는 데에 사용할 수 있으며, 이 과정을 **쓰기 경로**라 명명
- 시스템에 정보를 기록할 때마다 일괄 처리와 스트림 처리의 여러 단계를 거친 다음 결과정으로 모든 파생 데이터셋에 통합 갱신
- 파생 데이터 생성의 이유는 질의이며 이를 **읽기 경로**라고 명명
    - 사용자 요청을 할 떄 파생 데이터 셋을 읽고 가공하여 사용자 응답 제공
- 파생 데이터셋은 쓰기 경로와 읽기 경로가 만는 장소
    - 따라서 쓰기 시간에 필요한 작업의 양과 읽기 시간에 필요한 시간의 트레이드 오프

#### 구체화 뷰와 캐싱

- 전문 검색 색인은 좋은 예제
    - 키워드에서 AND나 OR 등의 논리 연산 추가
- 색인이 존재하지 않으면, 모든 문서 스캔 필요
    - 쓰기 경로 부담은 없지만 읽기 경로가 기하급수적 증가
- 모든 질의의 검색 결과를 캐싱해놓으면, 작업량이 줄어들지만 이는 비현실적
- 가장 공통 질의만 캐싱하는 방법이 있음
    - 이를 **공통 질의 캐시**

#### 오프라인 대응 가능한 상태 저장 클라이언트

- 과거와 달리 각 기기 모두 로컬 장치에 저장할 수 있어 모두 처리할 때 서버까지 반복할 필요 X
- 동기식 네트워크 요청을 반드시 처리하지 않는 **offline-first** 어플리케이션이 각광을 받음
- 클라이언트에서 상태를 유지하는 쪽으로 나아가면 새로운 기회가 옴

#### 상태 변경을 클라이언트에게 푸시하기

- 변경 사항을 폴링하지 않으면 신선도가 떨어지는 캐시
- 최신 프로토콜들이 HTTP의 기본적인 req/res 요청 패턴을 벗어남
    - 서버 전송 이벤트와 웹 소켓은 TCP 접속을 유지하면서 주도적으로 서버가 메시지를 브라우저에 보내는 통신 방식
    - 로컬의 저장된 상태가 변경되었을 때 서버에서 주도적으로 클라이언트가 신선도가 떨어지는 것을 방지
- 로그 기반 메시지 브로커를 통해 알림 전파 가능

#### 종단 간 스트림

- React, Flux, Redux 같은 상태 저장 클라이언트와 사용자 인터페이스 개발용 도구는 사용자 입력을 표현하는 이벤트 스트림 혹은 서버 응답 스트림을 구독하는 방식을 사용해 클라이언ㅇ트 상태 관리
    - 이벤트 소싱과 비슷
- 상태 변경은 종단 간 쓰기 경로에 따라 흐를 수 있음
    - 상호작용을 통해 이벤트 로그를 거쳐 파생 데이터 시스템과 스트림 처리자를 통해 다른 장치의 상태를 보고 있는 사용자 인터페이스까지 이어짐
- 쓰기 경로를 최종 사용자까지 확장하려면 근본적으로 시스템 재구축 필요
    - req/res 방식에서 벗어나 pub/sub Dataflow 방식으로 변경 필요
    - 데이터 시스템을 설계 한다면 현재 상태를 질의하는 방식이 아니라 변경 사항을 구독하는 방식으로 처리 필요

#### 읽기도 이벤트다

- 스트림 처리자가 파생 데이터를 저장소에 기록하거나 질의 요청을 할 때 읽기 경로와 쓰기 경로 사이의 경계 작동
    - 저장소는 임의 접근 읽기 질의가 가능
- 읽기는 질의 대상 데이터가 저장된 노드로 직접 보내는 일시적 네트워크 요청
    - 읽기 요청을 이벤트 스트림으로 표현하고, 읽기 이벤트와 쓰기 이벤트 모두를 스트림 처리자로 보내는 방법 또한 가능
- 쓰기와 읽기 모두 이벤트로 표현하고 처리하는 것은 스트림 테이블 조인 수행과 동일
- 일회성 읽기 요청은 조인 연산자를 통해 흘러가고 이후에 즉시 사라짐
    - 구독 요청은 과거, 미래 이벤트와의 영속적 조인
- 읽기 이벤트 로그를 기록하면, 인과적 의존성과 시스템 전체의 데이터 출처를 추적 가능
- 지속성 있는 저장소에 읽기 이벤트를 입력하면 추적하기 좋지만 I/O 비용 발 생 및 추가 저장소 필요

#### 다중 파티션 데이터 처리

- 스트림 처리자가 제공하는 메시지 라우팅 및 조인용 인프라를 이용하면 여러 파티션의 데이터 통합이 필요한 복잡한 질의를 분산 실행 할 수 있는 가능성 오픈
- 스톰 분산 RPC 기능이 이런 사용 패턴 지원
- 질의를 스트림으로 간주할 경우 대규모 어플리케이션 구현하는 방법이 생김

## 정확성을 목표로

- 신뢰성 있고 정확한 어플리케이션을 구축하기를 원함
- 일관성은 잘못 정의되기 함
- 동시성이 적고 결함이 없는 간단한 솔루션은 종종 정확하게 작동하는 것처럼 보이지만, 요구사항이 늘어갈 수록 버그가 늘어남
- 어플리케이션이 예측하지 못한 데이터의 깨짐이나 누락을 견딜 수 있다면 아키텍처는 단순
    - 직렬성이나 원자적 커밋은 확실하지만 비용이 많이 듬
    - 확장성과 내결함성 속성을 제한

### 데이터베이스에 관한 종단 간 논증

- 비교적 강력한 안전성 속성을 지원하는 데이터 시스템을 사용해도 데이터 유실과 손상이 없을 것이라는 보장 X

#### 연산자의 정확히 한 번 실행

- exactly at once에서는 실패 시 포기하거나 재시도 가능하며 재시도는 중복 위험성 존재
- 동일한 결과를 최종적으로 얻기 위해 계산을 조정
- 연산을 멱등으로 만듬

#### 중복 억제

- 스트림 처리 외에도 많은 곳에서 동일한 중복 제거 패턴이 발생
- 그러나 이러한 부분도 TCP 연결 문맥 내에서만 작동하기 때문에, 데이터베이스 트랜잭션 성공 여부는 불확실
- 데이터베이스 클라이언트와 서버 사이에서 중복 트랜잭션을 억제 가능하더라도 최종 사용자 장치와 서버 간 네트워크 상황도 고려 필요성은 존재

#### 연산 식별자

- 네트워크 통신을 통과하는 연산을 멱등성으로 만들기 위해서는 종단 간 흐름을 고려하여 고유 ID 사용하여 중복 요청을 억제해야 함

#### 종단 간 논증

- 중복 트랜잭션 억제 시나리오는 종단 간 논증 필요
- 최종 사용자 클라이언트부터 모든 경로에 트랜잭션 식별자를 포함하는 방법으로 가능
- 데이터 무결성 검사나 암호화에 적용 가능

#### 종단 간 사고를 데이터 시스템에 적용하기

- 결론적으로 어플리케이션 중복 억제와 같은 종단 간 대책을 갖출 필요가 있음
- 내결함성 매커니즘을 구현하기 어려움
- 트랜잭션은 매우 훌륭한 추상화이나 비용이 많이 듬
- 대규모 분산 환경에서도 좋은 운영적 특성을 유지하는 내결함성 추상화를 탐구하는 것이 가치 있음


### 제약조건 강제하기

- 유일성 제약 조건을 강제하기 위해서는 합의가 필요
    - 값이 같은 요청이 동시에 여러 개 존재한다면 시스템은 어떤 방식으로든 충돌한 연산 중 하나를 수용하고 나머지를 제약 조건 위반으로 거부해야 함
    - 합의를 달성하는 가장 일반적인 방법은 단일 노드를 리더로 만들고 해당 노드가 모든 결정을 하게끔 책임을 부여하는 것
- 유일성 검사는 유일성이 필요한 값을 기준으로 파티셔닝하면 확장 가능
- 비동기 마스터 복제는 충돌되는 쓰기를 받아들어 값이 더 이상 유일하지 않을 수 있기 때문에 쓸 수 없음
    - 제약 조건을 위반하면 어떤 쓰기도 즉시 거부하기를 원한다면 동기식 코디네이션이 필요

#### 유일성 제약 조건은 합의가 필요하다

- 유일성 제약 조건을 강제하기 위해서는 합의가 필요
    - 값이 같은 요청이 동시에 여러 개 존재한다면 시스템은 어떤 방식으로든 충돌한 연산 중 하나를 수용하고 나머지를 제약 조건 위반으로 거부
- 합의를 달성하는 가장 일반적인 방법은 단일 노드를 리더로 만들고 해당 노드가 모든 결정을 하게끔 책임을 부여하는 것
- 유일성 검사는 유일성이 필요한 값을 기준으로 파티셔닝하면 확장 가능
- 비동기 마스터 복제는 충돌되는 쓰기를 받아들어 값이 더 이상 유일하지 않을 수 있기 때문에 쓸 수 없음
    - 제약 조건을 위반하면 어떤 쓰기도 즉시 거부하기를 원한다면 동기식 코디네이션이 필요


#### 로그 기반 메시징의 유일성

- 로그는 모든 소비자가 동일한 순서로 메시지를 보도록 보장
    - 공식적으로 이 보장을 전체 순서 브로드캐스트(total order broadcast) 라 부르고 이것은 합의와 동일
    - 로그 기반 메시징을 사용하는 언번들링 데이터베이스 접근법에서 유일성 제약 조건을 강제하기 위해 매우 비슷한 접근법을 사용할 수 있음
- 스트림 처리자는 단일 스레드 상에서 한 로그 파티션의 모든 메시지를 순차적으로 소비합니다.
    - 유일성이 필요한 값을 기준으로 로그를 파티셔닝하면 스트림 처리자는 충돌이 발생한 연산 중 어떤 것이 처음 들어온 연산인지 분명하면서도 결정적으로 판결할 수 있음
- 파티션 수를 늘리면 쉽게 확장할 수 있어 대규모 요청을 처리할 수 있음
- 유일성 제약 조건뿐만 아니라 다른 많은 제약 조건에도 사용할 수 있음
    - 근본 원리는 충돌이 발생할 수 있는 쓰기를 모두 같은 파티션으로 라우팅하고 순서대로 처리

#### 다중 파티션 요청 처리

- 원자적 커밋이 없이 파티셔닝된 로그를 사용하면 동등성 정확성을 달성할 수 있음이 밝혀짐
- 클라이언트가 직접 입금 지시와 출금 지시를 보낸다면 둘 다 동시에 처리하거나 동시에 처리하지 않는 것을 보장하기 위해 두 파티션 간 원자적 커밋이 필요
    - 1단계와 2단계는 반드시 필요하며 분산 트랜잭션을 사용하지 않으려면 먼저 요청을 메시지 형태로 로그에 지속성 있게 남겨야 함
- 2단계에서 스트림 처리자에 장개가 발생하면 이전 체크포인트에서 처리를 재개
- 보내는 사람 계좌에서 중복 일출이 되지 않음을 보장하기 위해 추가적인 스트림 처리자를 사용 가능
- 다중 파티션 트랜잭션을 서로 다른 파티셔닝된 두 단계로 나누고 종단 간 요청 ID를 사용하면 결함 존재 여부와 상관없이, 그리고 원자적 커밋 프로토콜을 쓰지 않고도 동일한 정확성 속성을 달성 가능

### 적시성과 무결성
- 트랜직션의 한 가지 편리한 속성은 대개 선형성이 있다는 점
    - 기록자는 트랜잭션이 커밋될 때까지 기다리고 커밋 이후부터 해당 쓰기가 모든 독자에게 보임
    - 다중 단계로 스트림 처리자를 거쳐 연산을 언번들링하는 경우와 다름
- 일반적으로, 일관성이라는 용어는 두 가지 요구사항이 합쳐졌다고 여겨짐
    - 적시성(Timeliness), 사용자가 시스템을 항상 최신 상태로 관측 가능한 의미
    - 무결성(Integrity), 손상이 없다는 의미
- 적시성 위반은 "최종적 일관성"이고 무결성 위반은 "영구적 불일치"
- 적시성을 위반하면 성가시고 혼란스러울 수 있으나, 무결성을 위반하면 망함

#### 데이터 플로 시스템의 정확성

- ACID 트랜잭션은 대개 적시성과 무결성 양쪽 모두 보장
    - ACID 트랜잭션의 관점에서 애플리케이션 적확성을 접근한다면 적시성과 무결성을 따로 구별하는 것은 중요 X
- 이벤트 기반 데이터플로 시스템의 흥미로운 속성 하나가 적시성과 무결성을 분리하는 것입니다.
    - 무결성이 스트림 시스템의 핵심
- 정확히 한 번이나 결과적으로 한 번 시맨틱은 무결성은 보존하는 메커니즘
- 신뢰성 있는 스트림 처리 시스템은 분산 트랜잭션과 원자적 커밋 프로토콜 없이 무결성을 보존가능 
- 무결성은 아래 메커니즘의 결합을 통해 달성할 수 가능
    - 쓰기 연산을 단일 메시지로 표현하기
    - 결정적 파생 함수를 사용해 해당 단일 메시지에서 모든 상태 갱신을 파생하기
    - 클라이언트가 생성한 요청 ID를 모든 처리 단계를 통해 전달하기
    - 메시지를 불변으로 만들고 필요 시 파생 데이터 재처리하기

#### 느슨하게 해석되는 제약 조건

- 유일성 제약 조건을 강제하려면 합의가 필요
- 합의는 일반적으로 모든 이벤트를 단일 노드를 통해 특정 파티션으로 보내 처리하는 방식으로 구현
    - 많은 애플리케이션이 훨씬 완화된 유일성 개념을 사용해 이 제한을 피할 수 있음
- 두 사람이 동시에 같은 사용자명을 등록하거나 같으 좌석을 예약한다면, 두 사람 중 한 사람에게 사과 메시지를 보내 다른 이름이나 좌석을 고르게끔 부탁할 수 있고 이러한 종류의 변경 방법을 보상 트랜잭션이라 명명
- 많은 비즈니스 맥락에서 제약 조건을 일시적으로 위반하고 나중에 사과해 바로잡는 것은 실제로 수용 가능한 방법
- 애플리케이션은 무결성을 반드시 요구하기 때문에 예약을 놓치거나 입금액과 출금액이 일치하지 않아 돈이 사라지는 것은 좋지 않음 다만, 제약 조건을 강제하는 상황에서도 적시성은 반드시 필요한 것은 X

#### 코디네이션 회피 데이터 시스템

- 데이터플로 시스템은 원자적 커밋과 선형성, 그리고 파티션에 걸친 동기 코디네이션 없이도 팟애 데이터에 대한 무결성 보장을 유지할 수 있음
- 엄격한 유일성 제약 조건은 적시성과 코디네이션을 요구하지만 많은 애플리케이션은 느슨한 제약 조건을 사용해도 실제로 괜찮음
- 코디네이션 회피(coordination-avoiding) 데이터 시스템은 동기식 코디네이션이 필요한 시스템보다 성능이 더 좋고 더 나은 내결함성을 지님
- 애플리케이션의 작은 일부에서만 코디네이션이 필요하다면 모든 곳에서 코디네이션 비용을 지불할 필요는 없음
- 너무 많은 불일치나 너무 많은 가용성 문제가 없는 최적의 장소를 찾는 것이 목표

### 믿어라 하지만 확인하라

#### 소프트웨어 버그가 발생해도 무결성 유지하기

- 하드웨어 문제 외에 소프트웨어 버그의 위험성은 항상 존재
- 설계와 테스트, 리뷰를 신중하게 적지 않은 노력을 하더라도 버그는 여전히 생김
- 데이터베이스는 항상 일관성 있는 상태에 있으라고 기대하지만 트랜잭션에 버그가 없을 때만 통하기 때문에
    - 완화된 격리 수준을 안전하지 않게 사용하면 데이터베이스 무결성은 보장

#### 약속을 맹목적으로 믿지 마라

- 데이터 무결성을 체크하는 작업을 감사(auditing) 
- 데이터가 여전히 거기 있다고 확인하려면 실제로 파일을 읽어서 확인
- 맹목적으로 모든 것이 잘 동작한다고 믿지 않아야 함

#### 검증하는 문화

- HDFS나 S3 같은 시스템은 대부분 정확하게 장독한다고 가정
    - 일반적으로 합리적이지만 항상 올바르게 작동한다는 가정과 다름
- 미래에는 스스로 무결성확인을 지속하는 자가 검증(self-validation) 이나 자가 감사(self-auditing) 시스템을 기대

#### 감사 기능 설계

- 이벤트 기반 시스템은 더 나은 감사 시스템을 제공
- 데이터플로를 명시적으로 만들면 데이터의 유랙(provenance) 가 더욱 명확해져 무결성 확인이 좀 더 수월
- 결정적이고 잘 정의한 데이터플로를 사용하면 디버깅과 시스템에서 왜 그렇게 행동했는지 판별하기 위한 추적이 쉬워짐

#### 다시 종단 간 논증

- 시스템의 모든 개별 구성 요소가 절대로 손상되지 않는다고 완전히 믿기 어렵다면 최한 데이터의 무결성만이라도 주기적으로 확인 필요
- 데이터 시스템의 무결성을 확인하는 방법은 종단 간 방식이 최선
- 종단 간 무결성 확인을 꾸준히 함으로써 시스템이 정확하다는 확신이 높아짐

#### 감사 데이터 시스템용 도구

- 암호화 감사 기능과 무결성 확인은 종종 머클 트리(Merkle tree)에 의존
- 머클 트리는 해시 트리로 특정 데이터셋 내에 나타나는 레코드를 효율적으로 증명하는 데 사용
- 인증서 투명서(certificate transparency) 는 머클 트리를 사용해 TTS/SSL 인증 유효성을 확인하는 보안 기술

## 옳은 일 하기

### 예측 분석

#### 편견과 차별

- 차별 하지말기

#### 책임과 의무

- 데이터의 보조의 역할이지만 맹신은 금지

#### 피드백 루프

- 예측 분석 시 삶의 영향을 끼칠 때 치명적인 문제를 가짐

### 사생활과 추적

#### 감시

- 데이터는 곧 감시일 수도 있음

#### 동의와 선택의 자유

- 사실상 서비스 동의는 데이터 제공 강제

#### 사생활과 데이터 사용

- 사생활은 정보 보호 범위에 대한 권리

#### 자산과 권력으로서의 데이터

- 데이터는 가치 있기 때문에 이를 많이 지는 사람이 권력

#### 산업 혁명의 기억

- 

#### 법률과 자기 규제